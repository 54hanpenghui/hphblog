<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="baidu-site-verification" content="L6Lm9d5Crl"/>
  
  
  
  
  <title>Sqoop | 菜鸟清风</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Sqoop的基本原理和相关参数配置：">
<meta property="og:type" content="article">
<meta property="og:title" content="Sqoop">
<meta property="og:url" content="https://www.hphblog.cn/2019/01/08/Sqoop/index.html">
<meta property="og:site_name" content="菜鸟清风">
<meta property="og:description" content="Sqoop的基本原理和相关参数配置：">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://s2.ax1x.com/2019/01/08/FqsIJO.png">
<meta property="og:image" content="https://s2.ax1x.com/2019/01/08/FqyClQ.png">
<meta property="article:published_time" content="2019-01-08T05:16:45.000Z">
<meta property="article:modified_time" content="2020-01-12T13:08:07.817Z">
<meta property="article:author" content="清风笑丶">
<meta property="article:tag" content="Sqoop">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s2.ax1x.com/2019/01/08/FqsIJO.png">
  
    <link rel="alternative" href="/https://blog.csdn.net/weixin_39084521/rss/list" title="菜鸟清风" type="application/atom+xml">
  
  
    <link rel="icon" href="/img/favicon.png">
  
  
  
<link rel="stylesheet" href="//cdn.bootcss.com/animate.css/3.5.0/animate.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  <link rel="stylesheet" href="/font-awesome/css/font-awesome.min.css">
  <link rel="apple-touch-icon" href="/apple-touch-icon.png">
  
  
      <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  
  <!-- 加载特效 -->
    <script src="/js/pace.js"></script>
    <link href="/css/pace/pace-theme-flash.css" rel="stylesheet" />
  <script>
      var yiliaConfig = {
          fancybox: true,
          animate: true,
          isHome: false,
          isPost: true,
          isArchive: false,
          isTag: false,
          isCategory: false,
          open_in_new: false
      }
  </script>
<meta name="generator" content="Hexo 4.2.0"></head>
<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
    <header id="header" class="inner">
        
<script src="https://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js"></script>

        <a href="/" class="profilepic">
            
            <img lazy-src="/img/avatar.jpg" class="js-avatar">
            
        </a>
        <hgroup>
          <h1 class="header-author"><a href="/">清风笑丶</a></h1>
        </hgroup>
        
        
            <form>
                <input type="text" class="st-default-search-input search" id="local-search-input" placeholder="搜索一下" autocomplete="off">
            </form>
            <div id="local-search-result"></div>
        
        
            <script type="text/javascript">
                (function() {
                    'use strict';
                    function getMatchData(keyword, data) {
                        var matchData = [];
                        for(var i =0;i<data.length;i++){
                            if(data[i].title.toLowerCase().indexOf(keyword)>=0) 
                                matchData.push(data[i])
                        }
                        return matchData;
                    }
                    var $input = $('#local-search-input');
                    var $resultContent = $('#local-search-result');
                    $input.keyup(function(){
                        $.ajax({
                            url: '/search.json',
                            dataType: "json",
                            success: function( json ) {
                                var str='<ul class=\"search-result-list\">';                
                                var keyword = $input.val().trim().toLowerCase();
                                $resultContent.innerHTML = "";
                                if ($input.val().trim().length <= 0) {
                                    $resultContent.empty();
                                    $('#switch-area').show();
                                    return;
                                }
                                var results = getMatchData(keyword, json);
                                if(results.length === 0){
                                    $resultContent.empty();
                                    $('#switch-area').show();
                                    return;
                                } 
                                for(var i =0; i<results.length; i++){
                                    str += "<li><a href='"+ results[i].url +"' class='search-result-title'>"+ results[i].title +"</a></li>";
                                }
                                str += "</ul>";
                                $resultContent.empty();
                                $resultContent.append(str);
                                $('#switch-area').hide();
                            }
                        });
                    });
                })();
            </script>
        
        
            <div id="switch-btn" class="switch-btn">
                <div class="icon">
                    <div class="icon-ctn">
                        <div class="icon-wrap icon-house" data-idx="0">
                            <div class="birdhouse"></div>
                            <div class="birdhouse_holes"></div>
                        </div>
                        <div class="icon-wrap icon-ribbon hide" data-idx="1">
                            <div class="ribbon"></div>
                        </div>
                        
                        <div class="icon-wrap icon-link hide" data-idx="2">
                            <div class="loopback_l"></div>
                            <div class="loopback_r"></div>
                        </div>
                        
                        
                        <div class="icon-wrap icon-me hide" data-idx="3">
                            <div class="user"></div>
                            <div class="shoulder"></div>
                        </div>
                        
                    </div>
                </div>
                <div class="tips-box hide">
                    <div class="tips-arrow"></div>
                    <ul class="tips-inner">
                        <li>菜单</li>
                        <li>标签</li>
                        
                        <li>友情链接</li>
                        
                        
                        <li>关于我</li>
                        
                    </ul>
                </div>
            </div>
        
        <div id="switch-area" class="switch-area">
            <div class="switch-wrap">
                <section class="switch-part switch-part1">
                    <nav class="header-menu">
                        <ul>
                        
                            <li><a  href="/archives/">所有文章</a></li>
                        
                            <li><a  href="/categories/Java/">Java</a></li>
                        
                            <li><a  href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE">大数据</a></li>
                        
                            <li><a  href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93">数据库</a></li>
                        
                            <li><a  href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84">数据结构</a></li>
                        
                            <li><a  href="/about/">关于我</a></li>
                        
                        </ul>
                    </nav>
                    <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fl github"  target="_blank" href="https://github.com/bigdataxiaohan" title="github">github</a>
                            
                                <a class="fl zhihu"  target="_blank" href="https://www.zhihu.com/people/qing-feng-xiao-zhu-15/activities" title="zhihu">zhihu</a>
                            
                                <a class="fl mail"  target="_blank" href="mailto:467008580@qq.com" title="mail">mail</a>
                            
                        </ul>
                    </nav>
                </section>
                
                <section class="switch-part switch-part2">
                    <div class="widget tagcloud" id="js-tagcloud">
                        <a href="/tags/AVL%E6%A0%91/" style="font-size: 10px;">AVL树</a> <a href="/tags/Docker/" style="font-size: 14.44px;">Docker</a> <a href="/tags/Dubbo/" style="font-size: 10px;">Dubbo</a> <a href="/tags/Elasticsearch/" style="font-size: 17.78px;">Elasticsearch</a> <a href="/tags/Eureka/" style="font-size: 10px;">Eureka</a> <a href="/tags/Feign/" style="font-size: 10px;">Feign</a> <a href="/tags/Flink/" style="font-size: 10px;">Flink</a> <a href="/tags/Flume/" style="font-size: 11.11px;">Flume</a> <a href="/tags/Git/" style="font-size: 10px;">Git</a> <a href="/tags/GraphX/" style="font-size: 10px;">GraphX</a> <a href="/tags/HBase/" style="font-size: 11.11px;">HBase</a> <a href="/tags/HDFS/" style="font-size: 11.11px;">HDFS</a> <a href="/tags/Hadoop/" style="font-size: 13.33px;">Hadoop</a> <a href="/tags/Hbase/" style="font-size: 11.11px;">Hbase</a> <a href="/tags/Hive/" style="font-size: 13.33px;">Hive</a> <a href="/tags/Hystrix/" style="font-size: 10px;">Hystrix</a> <a href="/tags/JPA/" style="font-size: 10px;">JPA</a> <a href="/tags/JSP/" style="font-size: 10px;">JSP</a> <a href="/tags/JSR107/" style="font-size: 10px;">JSR107</a> <a href="/tags/JVM/" style="font-size: 14.44px;">JVM</a> <a href="/tags/JavaWeb/" style="font-size: 10px;">JavaWeb</a> <a href="/tags/Kafka/" style="font-size: 14.44px;">Kafka</a> <a href="/tags/MapReduce/" style="font-size: 14.44px;">MapReduce</a> <a href="/tags/Memcached/" style="font-size: 10px;">Memcached</a> <a href="/tags/MongoDB/" style="font-size: 15.56px;">MongoDB</a> <a href="/tags/Mybatis/" style="font-size: 15.56px;">Mybatis</a> <a href="/tags/Oozie/" style="font-size: 10px;">Oozie</a> <a href="/tags/RDD/" style="font-size: 14.44px;">RDD</a> <a href="/tags/REST/" style="font-size: 10px;">REST</a> <a href="/tags/RPC/" style="font-size: 10px;">RPC</a> <a href="/tags/RabbitMQ/" style="font-size: 11.11px;">RabbitMQ</a> <a href="/tags/Redis/" style="font-size: 15.56px;">Redis</a> <a href="/tags/Ribbon/" style="font-size: 10px;">Ribbon</a> <a href="/tags/SSM/" style="font-size: 11.11px;">SSM</a> <a href="/tags/SparKSQL/" style="font-size: 12.22px;">SparKSQL</a> <a href="/tags/Spark/" style="font-size: 20px;">Spark</a> <a href="/tags/SparkStreaming/" style="font-size: 12.22px;">SparkStreaming</a> <a href="/tags/Spring/" style="font-size: 14.44px;">Spring</a> <a href="/tags/Spring-Security/" style="font-size: 10px;">Spring Security</a> <a href="/tags/SpringBoot/" style="font-size: 16.67px;">SpringBoot</a> <a href="/tags/SpringBoot-Admin/" style="font-size: 10px;">SpringBoot Admin</a> <a href="/tags/SpringCloud/" style="font-size: 18.89px;">SpringCloud</a> <a href="/tags/SpringConfig/" style="font-size: 10px;">SpringConfig</a> <a href="/tags/SpringMVC/" style="font-size: 15.56px;">SpringMVC</a> <a href="/tags/Sqoop/" style="font-size: 10px;">Sqoop</a> <a href="/tags/Structured-Streaming/" style="font-size: 10px;">Structured Streaming</a> <a href="/tags/Thymeleaf/" style="font-size: 10px;">Thymeleaf</a> <a href="/tags/Zookeeper/" style="font-size: 11.11px;">Zookeeper</a> <a href="/tags/zuul/" style="font-size: 10px;">zuul</a> <a href="/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/" style="font-size: 11.11px;">二叉树</a> <a href="/tags/%E4%BB%BB%E5%8A%A1/" style="font-size: 10px;">任务</a> <a href="/tags/%E4%BC%98%E5%85%88%E9%98%9F%E5%88%97/" style="font-size: 10px;">优先队列</a> <a href="/tags/%E5%93%88%E5%B8%8C%E8%A1%A8/" style="font-size: 10px;">哈希表</a> <a href="/tags/%E5%A0%86/" style="font-size: 10px;">堆</a> <a href="/tags/%E5%AD%97%E5%85%B8%E6%A0%91/" style="font-size: 10px;">字典树</a> <a href="/tags/%E5%B9%B6%E6%9F%A5%E9%9B%86/" style="font-size: 10px;">并查集</a> <a href="/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/" style="font-size: 10px;">微服务</a> <a href="/tags/%E6%8A%80%E6%9C%AF%E9%80%89%E5%9E%8B/" style="font-size: 10px;">技术选型</a> <a href="/tags/%E6%95%B0%E7%BB%84/" style="font-size: 10px;">数组</a> <a href="/tags/%E6%97%A5%E5%BF%97%E6%A1%86%E6%9E%B6/" style="font-size: 10px;">日志框架</a> <a href="/tags/%E6%A0%88/" style="font-size: 10px;">栈</a> <a href="/tags/%E7%BA%A2%E9%BB%91%E6%A0%91/" style="font-size: 10px;">红黑树</a> <a href="/tags/%E7%BB%AA%E8%AE%BA/" style="font-size: 10px;">绪论</a> <a href="/tags/%E9%80%92%E5%BD%92/" style="font-size: 10px;">递归</a> <a href="/tags/%E9%93%BE%E8%A1%A8/" style="font-size: 10px;">链表</a> <a href="/tags/%E9%98%9F%E5%88%97/" style="font-size: 10px;">队列</a>
                    </div>
                </section>
                
                
                <section class="switch-part switch-part3">
                    <div id="js-friends">
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="https://blog.csdn.net/weixin_39084521?t=1">csdn</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="https://segmentfault.com/u/qingfengxiao">segmentfault</a>
                    
                      <a target="_blank"  class="main-nav-link switch-friends-link" href="https://www.jianshu.com/u/67dbb2933255">简书</a>
                    
                    </div>
                </section>
                
                
                
                <section class="switch-part switch-part4">
                
                    <div id="js-aboutme">文科男,理工芯。有借必有贷,有问必有答。</div>
                </section>
                
            </div>
        </div>
    </header>
</div>

    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
      <div class="overlay">
          <div class="slider-trigger"></div>
          <h1 class="header-author js-mobile-header hide"><a href="/" title="回到主页">清风笑丶</a></h1>
      </div>
    <div class="intrude-less">
        <header id="header" class="inner">
            <a href="/" class="profilepic">
                
                    <img lazy-src="/img/avatar.jpg" class="js-avatar">
                
            </a>
            <hgroup>
              <h1 class="header-author"><a href="/" title="回到主页">清风笑丶</a></h1>
            </hgroup>
            
            <nav class="header-menu">
                <ul>
                
                    <li><a href="/archives/">所有文章</a></li>
                
                    <li><a href="/categories/Java/">Java</a></li>
                
                    <li><a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE">大数据</a></li>
                
                    <li><a href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93">数据库</a></li>
                
                    <li><a href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84">数据结构</a></li>
                
                    <li><a href="/about/">关于我</a></li>
                
                <div class="clearfix"></div>
                </ul>
            </nav>
            <nav class="header-nav">
                <div class="social">
                    
                        <a class="github" target="_blank" href="https://github.com/bigdataxiaohan" title="github">github</a>
                    
                        <a class="zhihu" target="_blank" href="https://www.zhihu.com/people/qing-feng-xiao-zhu-15/activities" title="zhihu">zhihu</a>
                    
                        <a class="mail" target="_blank" href="mailto:467008580@qq.com" title="mail">mail</a>
                    
                </div>
            </nav>
        </header>
    </div>
</nav>
      <div class="body-wrap"><article id="post-Sqoop" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a  href="/2019/01/08/Sqoop/" class="article-date">
      <time datetime="2019-01-08T05:16:45.000Z" itemprop="datePublished">2019-01-08</time>
</a>

    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Sqoop
    </h1>
  


      </header>
      
      <div class="article-info article-info-post">
        
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a>
    </div>


        
    <div class="article-tag tagcloud">
        <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Sqoop/" rel="tag">Sqoop</a></li></ul>
    </div>

        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
          Sqoop的基本原理和相关参数配置：<Excerpt in index | 首页摘要><a id="more"></a>
<p>&lt;The rest of contents | 余下全文&gt;</p>
<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>Sqoop(发音：skup)是一款开源的工具，主要用于在Hadoop(Hive)与传统的数据库(mysql、postgresql…)间进行数据的传递，可以将一个关系型数据库<em>（例如 ： MySQL ,Oracle ,Postgres等）</em>中的数据导进到Hadoop的HDFS中，也可以将HDFS的数据导进到关系型数据库中。</p>
<p>Sqoop项目开始于2009年，最早是作为Hadoop的一个第三方模块存在，后来为了让使用者能够快速部署，也为了让开发人员能够更快速的迭代开发，Sqoop独立成为一个Apache项目。</p>
<h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><h3 id="导入"><a href="#导入" class="headerlink" title="导入"></a>导入</h3><p>在导入开始之前，Sqoop使用JDBC来检查将要导入的表。他检索出表中所有的列以及列的SQL数据类型。这些SQL类型（VARCHAR、INTEGER）被映射到Java数据类型（String、Integer等）,在MapReduce应用中将使用这些对应的java类型来保存字段的值。Sqoop的代码生成器使用这些信息来创建对应表的类，用于保存从表中抽取的记录。例如前面提到过的example类。</p>
<p>对于导入来说，更关键的是DBWritable接口的序列化方法，这些方法能使Widget类和JDBC进行交互：</p>
<p>​         Public void readFields(resultSet _dbResults)throws SQLException;</p>
<p>​         Public void write(PreparedStatement _dbstmt)throws SQLException;</p>
<p>JDBC的ResultSet接口提供了一个用户从检查结果中检索记录的游标；这里的readFields()方法将用ResultSet中一行数据的列来填充Example对象的字段。</p>
<p>Sqoop启动的MapReduce作业用到一个InputFormat,他可以通过JDBC从一个数据库表中读取部分内容。Hadoop提供的DataDriverDBInputFormat能够为几个Map任务对查询结果进行划分。为了获取更好的导入性能，查询会根据一个“划分列”来进行划分的。Sqoop会选择一个合适的列作为划分列（通常是表的主键）。</p>
<p>在生成反序列化代码和配置InputFormat之后，Sqoop将作业发送到MapReduce集群。Map任务将执行查询并将ResultSet中的数据反序列化到生成类的实例，这些数据要么直接保存在SequenceFile文件中，要么在写到HDFS之前被转换成分割的文本。</p>
<p>Sqoop不需要每次都导入整张表，用户也可以在查询中加入到where子句，以此来限定需要导入的记录：Sqoop –query (SQL)。</p>
<p>​         导入和一致性：在向HDFS导入数据时，重要的是要确保访问的是数据源的一致性快照。从一个数据库中并行读取数据的MAP任务分别运行在不同的进程中。因此，他们不能共享一个数据库任务。保证一致性的最好方法就是在导入时不允许运行任何进行对表中现有数据进行更新。</p>
<p><img src="https://s2.ax1x.com/2019/01/08/FqsIJO.png" alt="FqsIJO.png"></p>
<h3 id="导出"><a href="#导出" class="headerlink" title="导出"></a>导出</h3><p>Sqoop导出功能的架构与其导入功能非常相似，在执行导出操作之前，sqoop会根据数据库连接字符串来选择一个导出方法。一般为jdbc。然后，sqoop会根据目标表的定义生成一个java类。这个生成的类能够从文本文件中解析记录，并能够向表中插入类型合适的值。接着会启动一个MapReduce作业，从HDFS中读取源数据文件，使用生成的类解析记录，并且执行选定的导出方法。</p>
<p>基于jdbc的导出方法会产生一批insert语句，每条语句都会向目标表中插入多条记录。多个单独的线程被用于从HDFS读取数据并与数据库进行通信，以确保涉及不同系统的I/O操作能够尽可能重叠执行。</p>
<p>虽然HDFS读取数据的MapReduce作业大多根据所处理文件的数量和大小来选择并行度（map任务的数量），但sqoop的导出工具允许用户明确设定任务的数量。由于导出性能会受并行的数据库写入线程数量的影响，所以sqoop使用combinefileinput类将输入文件分组分配给少数几个map任务去执行。</p>
<p>系统使用固定大小的缓冲区来存储事务数据，这时一个任务中的所有操作不可能在一个事务中完成。因此，在导出操作进行过程中，提交过的中间结果都是可见的。在导出过程完成前，不要启动那些使用导出结果的应用程序，否则这些应用会看到不完整的导出结果。</p>
<p>更有问题的是，如果任务失败，他会从头开始重新导入自己负责的那部分数据，因此可能会插入重复的记录。当前sqoop还不能避免这种可能性。在启动导出作业前，应当在数据库中设置表的约束（例如，定义一个主键列）以保证数据行的唯一性。</p>
<p>​     Sqoop还可以将存储在SequenceFile中的记录导出到输出表，不过有一些限制。SequenceFile中可以保存任意类型的记录。Sqoop的导出工具从SequenceFile中读取对象，然后直接发送到OutputCollector，由他将这些对象传递给数据库导出OutputFormat。为了能让Sqoop使用，记录必须被保存在SequenceFile键值对格式的值部分，并且必须继承抽象类com.cloudera.sqoop.lib.SqoopRecord。</p>
<p><img src="https://s2.ax1x.com/2019/01/08/FqyClQ.png" alt="FqyClQ.png"></p>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><ol>
<li><p>下载软件 : <a href="http://mirrors.hust.edu.cn/apache/sqoop/1.4.6/" target="_blank" rel="noopener">http://mirrors.hust.edu.cn/apache/sqoop/1.4.6/</a></p>
</li>
<li><p>上传安装包sqoop-1.4.6.bin__hadoop-2.0.4-alpha.tar.gz到虚拟机中</p>
</li>
<li><p>软件到指定目录</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@datanode1 software]$ tar -zxvf sqoop-1.4.6.bin__hadoop-2.0.4-alpha.tar.gz -C /opt/module/</span><br><span class="line">[hadoop@datanode1 module]$ mv sqoop-1.4.6.bin__hadoop-2.0.4-alpha/ sqoop</span><br></pre></td></tr></table></figure>
</li>
<li><p>修改配置文件</p>
</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@datanode1 conf]$ mv sqoop-env-template.sh sqoop-env.sh</span><br><span class="line">[hadoop@datanode1 conf]$ mv sqoop-site-template.xml sqoop-site.xml</span><br></pre></td></tr></table></figure>

<ol start="5">
<li>修改配置文件sqoop-env.sh</li>
</ol>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Set path to where bin/hadoop is available</span></span><br><span class="line"><span class="attr">export</span> <span class="string">HADOOP_COMMON_HOME=/opt/module/hadoop</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Set path to where hadoop-*-core.jar is available</span></span><br><span class="line"><span class="attr">export</span> <span class="string">HADOOP_MAPRED_HOME=/opt/module/hadoop</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#set the path to where bin/hbase is available</span></span><br><span class="line"><span class="attr">export</span> <span class="string">HBASE_HOME=/opt/module/hbase</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Set the path to where bin/hive is available</span></span><br><span class="line"><span class="attr">export</span> <span class="string">HIVE_HOME=/opt/module/hive</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Set the path for where zookeper config dir is</span></span><br><span class="line"><span class="attr">export</span> <span class="string">ZOOKEEPER_HOME=/opt/module/zookeeper-3.4.10/</span></span><br><span class="line"><span class="attr">export</span> <span class="string">ZOOCFGDIR=$ZOOKEEPER_HOME/conf</span></span><br></pre></td></tr></table></figure>

<ol start="6">
<li>拷贝JDBC驱动sqoop的lib目录下</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp -a mysql-connector-java-5.1.27-bin.jar &#x2F;opt&#x2F;module&#x2F;sqoop&#x2F;lib</span><br></pre></td></tr></table></figure>

<ol start="7">
<li>验证Sqoop</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@datanode1 sqoop]$ bin/sqoop help</span><br><span class="line">Warning: /opt/module/sqoop/bin/../../hcatalog does not exist! HCatalog jobs will fail.</span><br><span class="line">Please set $HCAT_HOME to the root of your HCatalog installation.</span><br><span class="line">Warning: /opt/module/sqoop/bin/../../accumulo does not exist! Accumulo imports will fail.</span><br><span class="line">Please set $ACCUMULO_HOME to the root of your Accumulo installation.</span><br><span class="line">-----------------------------------------------------------------------------------------</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#上面的警告可以忽略</span></span></span><br><span class="line">19/01/08 13:35:58 INFO sqoop.Sqoop: Running Sqoop version: 1.4.6</span><br><span class="line">usage: sqoop COMMAND [ARGS]</span><br><span class="line"></span><br><span class="line">Available commands:</span><br><span class="line">  codegen            Generate code to interact with database records</span><br><span class="line">  create-hive-table  Import a table definition into Hive</span><br><span class="line">  eval               Evaluate a SQL statement and display the results</span><br><span class="line">  export             Export an HDFS directory to a database table</span><br><span class="line">  help               List available commands</span><br><span class="line">  import             Import a table from a database to HDFS</span><br><span class="line">  import-all-tables  Import tables from a database to HDFS</span><br><span class="line">  import-mainframe   Import datasets from a mainframe server to HDFS</span><br><span class="line">  job                Work with saved jobs</span><br><span class="line">  list-databases     List available databases on a server</span><br><span class="line">  list-tables        List available tables in a database</span><br><span class="line">  merge              Merge results of incremental imports</span><br><span class="line">  metastore          Run a standalone Sqoop metastore</span><br><span class="line">  version            Display version information</span><br><span class="line"></span><br><span class="line">See 'sqoop help COMMAND' for information on a specific command.</span><br></pre></td></tr></table></figure>

<ol start="8">
<li>测试是否成功连接数据库</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@datanode1 sqoop]$ bin&#x2F;sqoop list-databases --connect jdbc:mysql:&#x2F;&#x2F;datanode1:3306&#x2F; --username root --password 123456</span><br><span class="line">19&#x2F;01&#x2F;08 13:38:11 INFO sqoop.Sqoop: Running Sqoop version: 1.4.6</span><br><span class="line">19&#x2F;01&#x2F;08 13:38:11 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.</span><br><span class="line">19&#x2F;01&#x2F;08 13:38:12 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.</span><br><span class="line">information_schema</span><br><span class="line">metastore</span><br><span class="line">mysql</span><br><span class="line">mysqlsource</span><br><span class="line">performance_schema</span><br><span class="line">[hadoop@datanode1 sqoop]$</span><br></pre></td></tr></table></figure>

<h2 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h2><h3 id="导入数据"><a href="#导入数据" class="headerlink" title="导入数据"></a>导入数据</h3><h4 id="RDBMS到HDFS"><a href="#RDBMS到HDFS" class="headerlink" title="RDBMS到HDFS"></a>RDBMS到HDFS</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql) create database student;</span><br><span class="line">mysql) create table student.class(id int(4) primary key not null auto_increment, name varchar(255), age int);</span><br></pre></td></tr></table></figure>

<p>数据库脚本</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@datanode1 sqoop]$ vim mysql.sh</span><br><span class="line">STNAME="192.168.1.101"    #数据库信息</span><br><span class="line">PORT="3306"</span><br><span class="line">USERNAME="root"</span><br><span class="line">PASSWORD="123456"</span><br><span class="line"></span><br><span class="line">DBNAME="student"        #数据库名称</span><br><span class="line">TABLENAME="class"         #数据库中表的名称</span><br><span class="line"></span><br><span class="line">for ((i=1;i(=100;i++))              ##添加100条数据</span><br><span class="line">do</span><br><span class="line">insert_sql="insert into $&#123;TABLENAME&#125;(name,age) values('student_$i',($RANDOM%4)+18)"</span><br><span class="line">mysql -h$&#123;HOSTNAME&#125;  -P$&#123;PORT&#125;  -u$&#123;USERNAME&#125; -p$&#123;PASSWORD&#125; $&#123;DBNAME&#125; -e  "$&#123;insert_sql&#125;"</span><br></pre></td></tr></table></figure>

<h5 id="全部导入"><a href="#全部导入" class="headerlink" title="全部导入"></a>全部导入</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop import \</span><br><span class="line">--connect jdbc:mysql://datanode1:3306/student \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456 \</span><br><span class="line">--table class \</span><br><span class="line">--target-dir /student/class \</span><br><span class="line">--delete-target-dir \</span><br><span class="line">--num-mappers 1 \</span><br><span class="line">--fields-terminated-by "\t"</span><br></pre></td></tr></table></figure>

<h5 id="查询导入"><a href="#查询导入" class="headerlink" title="查询导入"></a><strong>查询导入</strong></h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"> bin/sqoop import \</span><br><span class="line">--connect jdbc:mysql://datanode1:3306/student \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456 \</span><br><span class="line">--target-dir /student/class_query \</span><br><span class="line">--delete-target-dir \</span><br><span class="line">--num-mappers 1 \</span><br><span class="line">--fields-terminated-by "\t" \</span><br><span class="line">--query 'select name,age from class where id (=20 and $CONDITIONS;'</span><br></pre></td></tr></table></figure>

<p>注意:must contain ‘$CONDITIONS’ in WHERE clause.</p>
<p>如果query后使用的是双引号，则$CONDITIONS前必须加转移符，防止shell识别为自己的变量。</p>
<p>–query选项，不能同时与–table选项使用</p>
<h5 id="导入指定列"><a href="#导入指定列" class="headerlink" title="导入指定列"></a>导入指定列</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop import \</span><br><span class="line">--connect jdbc:mysql://datanode1:3306/student \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456 \</span><br><span class="line">--target-dir /student/ \</span><br><span class="line">--delete-target-dir \</span><br><span class="line">--num-mappers 1 \</span><br><span class="line">--fields-terminated-by "\t" \</span><br><span class="line">--columns id,name \</span><br><span class="line">--table class</span><br></pre></td></tr></table></figure>

<p>注意:columns中如果涉及到多列，用逗号分隔，分隔时不要添加空格</p>
<h5 id="使用sqoop关键字筛选查询导入数据"><a href="#使用sqoop关键字筛选查询导入数据" class="headerlink" title="使用sqoop关键字筛选查询导入数据"></a>使用sqoop关键字筛选查询导入数据</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop import \</span><br><span class="line">--connect jdbc:mysql://datanode1:3306/student \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456 \</span><br><span class="line">--target-dir /student/limit \</span><br><span class="line">--delete-target-dir \</span><br><span class="line">--num-mappers 1 \</span><br><span class="line">--fields-terminated-by "\t" \</span><br><span class="line">--table class \</span><br><span class="line">--where "id(10"</span><br></pre></td></tr></table></figure>



<h4 id="RDBMS到Hive"><a href="#RDBMS到Hive" class="headerlink" title="RDBMS到Hive"></a>RDBMS到Hive</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">  bin/sqoop import \</span><br><span class="line">--connect jdbc:mysql://datanode1:3306/student \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456 \ </span><br><span class="line">--table class \</span><br><span class="line">--num-mappers 1 \</span><br><span class="line">--hive-import \</span><br><span class="line">--fields-terminated-by "\t" \</span><br><span class="line">--columns name,age \</span><br><span class="line">--hive-overwrite \</span><br><span class="line">--hive-table class_hive</span><br></pre></td></tr></table></figure>

<p>该过程分为两步:</p>
<p>第一步将数据导入到HDFS  默认临时目录是/user/admin/表名</p>
<p>第二步将导入到HDFS的数据迁移到Hive仓库</p>
<h4 id="RDBMS到HBase"><a href="#RDBMS到HBase" class="headerlink" title="RDBMS到HBase"></a>RDBMS到HBase</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;sqoop import  \</span><br><span class="line">--connect jdbc:mysql:&#x2F;&#x2F;datanode1:3306&#x2F;student  \</span><br><span class="line">--username &#39;root&#39;  \</span><br><span class="line">--password &#39;123456&#39;   \</span><br><span class="line">--table &#39;class&#39;  \</span><br><span class="line">--hbase-table &#39;test&#39;   \</span><br><span class="line">--hbase-row-key &#39;id&#39;  \</span><br><span class="line"> --column-family &#39;info&#39;</span><br></pre></td></tr></table></figure>

<p>需要先创建hbase表</p>
<h3 id="导出数据"><a href="#导出数据" class="headerlink" title="导出数据"></a>导出数据</h3><h4 id="HIVE到RDBMS"><a href="#HIVE到RDBMS" class="headerlink" title="HIVE到RDBMS"></a>HIVE到RDBMS</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;sqoop export \</span><br><span class="line">--connect jdbc:mysql:&#x2F;&#x2F;datanode1:3306&#x2F;student \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456 \</span><br><span class="line">--table class_from_hive \</span><br><span class="line">--num-mappers 1 \</span><br><span class="line">--export-dir &#x2F;user&#x2F;hive&#x2F;warehouse&#x2F;class_hive \</span><br><span class="line">--input-fields-terminated-by &quot;\t&quot;</span><br></pre></td></tr></table></figure>

<p>表要先创先好</p>
<h4 id="HDFS到RDBMS"><a href="#HDFS到RDBMS" class="headerlink" title="HDFS到RDBMS"></a>HDFS到RDBMS</h4> <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">mkdir opt</span><br><span class="line"> vi opt/job_HDFS2RDBMS.opt</span><br><span class="line">export --connect</span><br><span class="line">jdbc:mysql://linux01:3306/company</span><br><span class="line">--username</span><br><span class="line">root</span><br><span class="line">--password</span><br><span class="line">123456</span><br><span class="line">--table</span><br><span class="line">staff</span><br><span class="line">--num-mappers</span><br><span class="line">1</span><br><span class="line">--export-dir</span><br><span class="line">/user/hive/warehouse/staff_hive</span><br><span class="line">--input-fields-terminated-by</span><br><span class="line">"\t"</span><br><span class="line"></span><br><span class="line"> bin/sqoop --options-file opt/job_HDFS2RDBMS.opt</span><br></pre></td></tr></table></figure>

<h4 id="Sqoop-常用参数"><a href="#Sqoop-常用参数" class="headerlink" title="Sqoop 常用参数"></a>Sqoop 常用参数</h4><table>
<thead>
<tr>
<th><strong>序号</strong></th>
<th><strong>命令</strong></th>
<th><strong>类</strong></th>
<th><strong>说明</strong></th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>import</td>
<td>ImportTool</td>
<td>将数据导入到集群</td>
</tr>
<tr>
<td>2</td>
<td>export</td>
<td>ExportTool</td>
<td>将集群数据导出</td>
</tr>
<tr>
<td>3</td>
<td>codegen</td>
<td>CodeGenTool</td>
<td>获取数据库中某张表数据生成Java并打包Jar</td>
</tr>
<tr>
<td>4</td>
<td>create-hive-table</td>
<td>CreateHiveTableTool</td>
<td>创建Hive表</td>
</tr>
<tr>
<td>5</td>
<td>eval</td>
<td>EvalSqlTool</td>
<td>查看SQL执行结果</td>
</tr>
<tr>
<td>6</td>
<td>import-all-tables</td>
<td>ImportAllTablesTool</td>
<td>导入某个数据库下所有表到HDFS中</td>
</tr>
<tr>
<td>7</td>
<td>job</td>
<td>JobTool</td>
<td>用来生成一个sqoop的任务，生成后，该任务并不执行，除非使用命令执行该任务。</td>
</tr>
<tr>
<td>8</td>
<td>list-databases</td>
<td>ListDatabasesTool</td>
<td>列出所有数据库名</td>
</tr>
<tr>
<td>9</td>
<td>list-tables</td>
<td>ListTablesTool</td>
<td>列出某个数据库下所有表</td>
</tr>
<tr>
<td>10</td>
<td>merge</td>
<td>MergeTool</td>
<td>将HDFS中不同目录下面的数据合在一起，并存放在指定的目录中</td>
</tr>
<tr>
<td>11</td>
<td>metastore</td>
<td>MetastoreTool</td>
<td>记录sqoop job的元数据信息，如果不启动metastore实例，则默认的元数据存储目录为：~/.sqoop，如果要更改存储目录，可以在配置文件sqoop-site.xml中进行更改。</td>
</tr>
<tr>
<td>12</td>
<td>help</td>
<td>HelpTool</td>
<td>打印sqoop帮助信息</td>
</tr>
<tr>
<td>13</td>
<td>version</td>
<td>VersionTool</td>
<td>打印sqoop版本信息</td>
</tr>
</tbody></table>
<h5 id="import"><a href="#import" class="headerlink" title="import"></a>import</h5><table>
<thead>
<tr>
<th><strong>序号</strong></th>
<th><strong>参数</strong></th>
<th><strong>说明</strong></th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>–enclosed-by (char)</td>
<td>给字段值前后加上指定的字符</td>
</tr>
<tr>
<td>2</td>
<td>–escaped-by (char)</td>
<td>对字段中的双引号加转义符</td>
</tr>
<tr>
<td>3</td>
<td>–fields-terminated-by (char)</td>
<td>设定每个字段是以什么符号作为结束，默认为逗号</td>
</tr>
<tr>
<td>4</td>
<td>–lines-terminated-by (char)</td>
<td>设定每行记录之间的分隔符，默认是\n</td>
</tr>
<tr>
<td>5</td>
<td>–mysql-delimiters</td>
<td>Mysql默认的分隔符设置，字段之间以逗号分隔，行之间以\n分隔，默认转义符是\，字段值以单引号包裹。</td>
</tr>
<tr>
<td>6</td>
<td>–optionally-enclosed-by (char)</td>
<td>给带有双引号或单引号的字段值前后加上指定字符。</td>
</tr>
</tbody></table>
<h5 id="export"><a href="#export" class="headerlink" title="export"></a>export</h5><table>
<thead>
<tr>
<th><strong>序号</strong></th>
<th><strong>参数</strong></th>
<th><strong>说明</strong></th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>–input-enclosed-by (char)</td>
<td>对字段值前后加上指定字符</td>
</tr>
<tr>
<td>2</td>
<td>–input-escaped-by (char)</td>
<td>对含有转移符的字段做转义处理</td>
</tr>
<tr>
<td>3</td>
<td>–input-fields-terminated-by (char)</td>
<td>字段之间的分隔符</td>
</tr>
<tr>
<td>4</td>
<td>–input-lines-terminated-by (char)</td>
<td>行之间的分隔符</td>
</tr>
<tr>
<td>5</td>
<td>–input-optionally-enclosed-by (char)</td>
<td>给带有双引号或单引号的字段前后加上指定字符</td>
</tr>
</tbody></table>
<h5 id="hive"><a href="#hive" class="headerlink" title="hive"></a>hive</h5><table>
<thead>
<tr>
<th><strong>序号</strong></th>
<th><strong>参数</strong></th>
<th><strong>说明</strong></th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>–hive-delims-replacement (arg)</td>
<td>用自定义的字符串替换掉数据中的\r\n和\013 \010等字符</td>
</tr>
<tr>
<td>2</td>
<td>–hive-drop-import-delims</td>
<td>在导入数据到hive时，去掉数据中的\r\n\013\010这样的字符</td>
</tr>
<tr>
<td>3</td>
<td>–map-column-hive (map)</td>
<td>生成hive表时，可以更改生成字段的数据类型</td>
</tr>
<tr>
<td>4</td>
<td>–hive-partition-key</td>
<td>创建分区，后面直接跟分区名，分区字段的默认类型为string</td>
</tr>
<tr>
<td>5</td>
<td>–hive-partition-value (v)</td>
<td>导入数据时，指定某个分区的值</td>
</tr>
<tr>
<td>6</td>
<td>–hive-home (dir)</td>
<td>hive的安装目录，可以通过该参数覆盖之前默认配置的目录</td>
</tr>
<tr>
<td>7</td>
<td>–hive-import</td>
<td>将数据从关系数据库中导入到hive表中</td>
</tr>
<tr>
<td>8</td>
<td>–hive-overwrite</td>
<td>覆盖掉在hive表中已经存在的数据</td>
</tr>
<tr>
<td>9</td>
<td>–create-hive-table</td>
<td>默认是false，即，如果目标表已经存在了，那么创建任务失败。</td>
</tr>
<tr>
<td>10</td>
<td>–hive-table</td>
<td>后面接要创建的hive表,默认使用MySQL的表名</td>
</tr>
<tr>
<td>11</td>
<td>–table</td>
<td>指定关系数据库的表名</td>
</tr>
</tbody></table>
<h4 id="Sqoop常用命令"><a href="#Sqoop常用命令" class="headerlink" title="Sqoop常用命令"></a>Sqoop常用命令</h4><h5 id="import-1"><a href="#import-1" class="headerlink" title="import"></a>import</h5><ol>
<li>导入数据到HIVE中</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop import   \</span><br><span class="line">--connect jdbc:mysql://datanode1:3306/student  \</span><br><span class="line">--username root  \</span><br><span class="line">--password 123456  \</span><br><span class="line">--table class    \</span><br><span class="line">--hive-import</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>增量导入数据到hive中，mode=append</li>
</ol>
<p>给MySQL添加几条数据</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"> bin/sqoop import \</span><br><span class="line">--connect jdbc:mysql://datanode1:3306/student \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456 \</span><br><span class="line">--table class \</span><br><span class="line">--num-mappers 1 \</span><br><span class="line">--fields-terminated-by "\t" \</span><br><span class="line">--target-dir /user/hive/warehouse/class \</span><br><span class="line">--check-column id \</span><br><span class="line">--incremental append \</span><br><span class="line">--last-value 3</span><br></pre></td></tr></table></figure>

<p>注意:append不能与–hive-等参数同时使用（Append mode for hive imports is not yet supported. Please remove the<br>parameter –append-mode）</p>
<p> 使用lastmodified方式导入数据要指定增量数据是要–append（追加）还是要–merge-key（合并）：last-value指定的值是会包含于增量导入的数据中</p>
<table>
<thead>
<tr>
<th><strong>序号</strong></th>
<th><strong>参数</strong></th>
<th><strong>说明</strong></th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>–append</td>
<td>将数据追加到HDFS中已经存在的DataSet中，如果使用该参数，sqoop会把数据先导入到临时文件目录，再合并。</td>
</tr>
<tr>
<td>2</td>
<td>–as-avrodatafile</td>
<td>将数据导入到一个Avro数据文件中</td>
</tr>
<tr>
<td>3</td>
<td>–as-sequencefile</td>
<td>将数据导入到一个sequence文件中</td>
</tr>
<tr>
<td>4</td>
<td>–as-textfile</td>
<td>将数据导入到一个普通文本文件中</td>
</tr>
<tr>
<td>5</td>
<td>–boundary-query (statement)</td>
<td>边界查询，导入的数据为该参数的值（一条sql语句）所执行的结果区间内的数据。</td>
</tr>
<tr>
<td>6</td>
<td>–columns   &lt;col1, col2, col3&gt;</td>
<td>指定要导入的字段</td>
</tr>
<tr>
<td>7</td>
<td>–direct</td>
<td>直接导入模式，使用的是关系数据库自带的导入导出工具，以便加快导入导出过程。</td>
</tr>
<tr>
<td>8</td>
<td>–direct-split-size</td>
<td>在使用上面direct直接导入的基础上，对导入的流按字节分块，即达到该阈值就产生一个新的文件</td>
</tr>
<tr>
<td>9</td>
<td>–inline-lob-limit</td>
<td>设定大对象数据类型的最大值</td>
</tr>
<tr>
<td>10</td>
<td>–m或–num-mappers</td>
<td>启动N个map来并行导入数据，默认4个。</td>
</tr>
<tr>
<td>11</td>
<td>–query或–e (statement)</td>
<td>将查询结果的数据导入，使用时必须伴随参–target-dir，–hive-table，如果查询中有where条件，则条件后必须加上$CONDITIONS关键字</td>
</tr>
<tr>
<td>12</td>
<td>–split-by   &lt;column-name)</td>
<td>按照某一列来切分表的工作单元，不能与–autoreset-to-one-mapper连用（请参考官方文档）</td>
</tr>
<tr>
<td>13</td>
<td>–table   (table-name)</td>
<td>关系数据库的表名</td>
</tr>
<tr>
<td>14</td>
<td>–target-dir   (dir)</td>
<td>指定HDFS路径</td>
</tr>
<tr>
<td>15</td>
<td>–warehouse-dir   (dir)</td>
<td>与14参数不能同时使用，导入数据到HDFS时指定的目录</td>
</tr>
<tr>
<td>16</td>
<td>–where</td>
<td>从关系数据库导入数据时的查询条件</td>
</tr>
<tr>
<td>17</td>
<td>–z或–compress</td>
<td>允许压缩</td>
</tr>
<tr>
<td>18</td>
<td>–compression-codec</td>
<td>指定hadoop压缩编码类，默认为gzip(Use Hadoop codec default gzip)</td>
</tr>
<tr>
<td>19</td>
<td>–null-string   (null-string)</td>
<td>string类型的列如果null，替换为指定字符串</td>
</tr>
<tr>
<td>20</td>
<td>–null-non-string   (null-string)</td>
<td>非string类型的列如果null，替换为指定字符串</td>
</tr>
<tr>
<td>21</td>
<td>–check-column   (col)</td>
<td>作为增量导入判断的列名</td>
</tr>
<tr>
<td>22</td>
<td>–incremental   (mode)</td>
<td>mode：append或lastmodified</td>
</tr>
<tr>
<td>23</td>
<td>–last-value   (value)</td>
<td>指定某一个值，用于标记增量导入的位置</td>
</tr>
</tbody></table>
<h5 id="export-1"><a href="#export-1" class="headerlink" title="export"></a>export</h5><p>从HDFS（包括Hive和HBase）中把数据导出到关系型数据库中。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop export \</span><br><span class="line">--connect jdbc:mysql://datanode1:3306/student \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456 \</span><br><span class="line">--table class2mysql \</span><br><span class="line">--export-dir /student \</span><br><span class="line">--input-fields-terminated-by "\t" \</span><br><span class="line">--num-mappers 1</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th><strong>序号</strong></th>
<th><strong>参数</strong></th>
<th><strong>说明</strong></th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>–direct</td>
<td>利用数据库自带的导入导出工具，以便于提高效率</td>
</tr>
<tr>
<td>2</td>
<td>–export-dir <dir></td>
<td>存放数据的HDFS的源目录</td>
</tr>
<tr>
<td>3</td>
<td>-m或–num-mappers <n></td>
<td>启动N个map来并行导入数据，默认4个</td>
</tr>
<tr>
<td>4</td>
<td>–table <table-name></td>
<td>指定导出到哪个RDBMS中的表</td>
</tr>
<tr>
<td>5</td>
<td>–update-key <col-name></td>
<td>对某一列的字段进行更新操作</td>
</tr>
<tr>
<td>6</td>
<td>–update-mode <mode></td>
<td>updateonly   allowinsert(默认)</td>
</tr>
<tr>
<td>7</td>
<td>–input-null-string <null-string></td>
<td>请参考import该类似参数说明</td>
</tr>
<tr>
<td>8</td>
<td>–input-null-non-string   <null-string></td>
<td>请参考import该类似参数说明</td>
</tr>
<tr>
<td>9</td>
<td>–staging-table   <staging-table-name></td>
<td>创建一张临时表，用于存放所有事务的结果，然后将所有事务结果一次性导入到目标表中，防止错误。</td>
</tr>
<tr>
<td>10</td>
<td>–clear-staging-table</td>
<td>如果第9个参数非空，则可以在导出操作执行前，清空临时事务结果表</td>
</tr>
</tbody></table>
<h5 id="codegen"><a href="#codegen" class="headerlink" title="codegen"></a>codegen</h5><p>将关系型数据库中的表映射为一个Java类，在该类中有各列对应的各个字段。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"> bin/sqoop codegen \</span><br><span class="line">--connect jdbc:mysql://datanode1:3306/student \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456 \</span><br><span class="line">--table class \</span><br><span class="line">--bindir /opt/moudle \</span><br><span class="line">--class-name class_mysql \</span><br><span class="line">--fields-terminated-by "\t"</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th><strong>序号</strong></th>
<th><strong>参数</strong></th>
<th><strong>说明</strong></th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>–bindir <dir></td>
<td>指定生成的Java文件、编译成的class文件及将生成文件打包为jar的文件输出路径</td>
</tr>
<tr>
<td>2</td>
<td>–class-name <name></td>
<td>设定生成的Java文件指定的名称</td>
</tr>
<tr>
<td>3</td>
<td>–outdir <dir></td>
<td>生成Java文件存放的路径</td>
</tr>
<tr>
<td>4</td>
<td>–package-name <name></td>
<td>包名，如com.z，就会生成com和z两级目录</td>
</tr>
<tr>
<td>5</td>
<td>–input-null-non-string <null-str></td>
<td>在生成的Java文件中，可以将null字符串或者不存在的字符串设置为想要设定的值（例如空字符串）</td>
</tr>
<tr>
<td>6</td>
<td>–input-null-string <null-str></td>
<td>将null字符串替换成想要替换的值（一般与5同时使用）</td>
</tr>
<tr>
<td>7</td>
<td>–map-column-java   <arg></td>
<td>数据库字段在生成的Java文件中会映射成各种属性，且默认的数据类型与数据库类型保持对应关系。该参数可以改变默认类型，例如：–map-column-java id=long, name=String</td>
</tr>
<tr>
<td>8</td>
<td>–null-non-string   <null-str></td>
<td>在生成Java文件时，可以将不存在或者null的字符串设置为其他值</td>
</tr>
<tr>
<td>9</td>
<td>–null-string   <null-str></td>
<td>在生成Java文件时，将null字符串设置为其他值（一般与8同时使用）</td>
</tr>
<tr>
<td>10</td>
<td>–table   <table-name></td>
<td>对应关系数据库中的表名，生成的Java文件中的各个属性与该表的各个字段一一对应</td>
</tr>
</tbody></table>
<h5 id="eval"><a href="#eval" class="headerlink" title="eval"></a>eval</h5><p>可以快速的使用SQL语句对关系型数据库进行操作，经常用于在import数据之前，了解一下SQL语句是否正确，数据是否正常，并可以将结果显示在控制台。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop eval \</span><br><span class="line">--connect jdbc:mysql://datanode1:3306/student \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456 \</span><br><span class="line">--query "SELECT * FROM class"</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th><strong>序号</strong></th>
<th><strong>参数</strong></th>
<th><strong>说明</strong></th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>–query或–e</td>
<td>后跟查询的SQL语句</td>
</tr>
</tbody></table>
<h5 id="import-all-tables"><a href="#import-all-tables" class="headerlink" title="import-all-tables"></a>import-all-tables</h5><p>可以将RDBMS中的所有表导入到HDFS中，每一个表都对应一个HDFS目录</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;sqoop import-all-tables \</span><br><span class="line">--connect jdbc:mysql:&#x2F;&#x2F;datanode1:3306&#x2F;student \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456 \</span><br><span class="line">--warehouse-dir &#x2F;all_tables</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th><strong>序号</strong></th>
<th><strong>参数</strong></th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>–as-avrodatafile</td>
</tr>
<tr>
<td>2</td>
<td>–as-sequencefile</td>
</tr>
<tr>
<td>3</td>
<td>–as-textfile</td>
</tr>
<tr>
<td>4</td>
<td>–direct</td>
</tr>
<tr>
<td>5</td>
<td>–direct-split-size <n></td>
</tr>
<tr>
<td>6</td>
<td>–inline-lob-limit <n></td>
</tr>
<tr>
<td>7</td>
<td>–m或—num-mappers <n></td>
</tr>
<tr>
<td>8</td>
<td>–warehouse-dir <dir></td>
</tr>
<tr>
<td>9</td>
<td>-z或–compress</td>
</tr>
<tr>
<td>10</td>
<td>–compression-codec</td>
</tr>
</tbody></table>
<h5 id="job"><a href="#job" class="headerlink" title="job"></a>job</h5><p>用来生成一个sqoop任务，生成后不会立即执行，需要手动执行。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ bin&#x2F;sqoop job \</span><br><span class="line"> --create myjob -- import-all-tables \</span><br><span class="line"> --connect jdbc:mysql:&#x2F;&#x2F;datanode1:3306&#x2F;student \</span><br><span class="line"> --username root \</span><br><span class="line"> --password 123456</span><br><span class="line">$ bin&#x2F;sqoop job --list</span><br><span class="line">$ bin&#x2F;sqoop job --exec myjob</span><br></pre></td></tr></table></figure>

<p>list-databases</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop list-databases \</span><br><span class="line">--connect jdbc:mysql://datanode1:3306/ \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456</span><br></pre></td></tr></table></figure>

<h5 id="list-tables"><a href="#list-tables" class="headerlink" title="list-tables"></a>list-tables</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">bin/sqoop list-tables \</span><br><span class="line">--connect jdbc:mysql://datanode1:3306/student \</span><br><span class="line">--username root \</span><br><span class="line">--password 123456</span><br></pre></td></tr></table></figure>

<h5 id="merge"><a href="#merge" class="headerlink" title="merge"></a>merge</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;sqoop codegen \</span><br><span class="line">--connect jdbc:mysql:&#x2F;&#x2F;datanode1&#x2F;student \</span><br><span class="line">--username root  \</span><br><span class="line">--password 123456 \</span><br><span class="line">--table class  \</span><br><span class="line">--bindir &#x2F;home&#x2F;hadoop  \</span><br><span class="line">--class-name student    \</span><br><span class="line">--fields-terminated-by &quot;\t&quot;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"> bin&#x2F;sqoop merge  \</span><br><span class="line">--new-data &#x2F;test&#x2F;new  \</span><br><span class="line">--onto &#x2F;test&#x2F;old  \</span><br><span class="line">--target-dir &#x2F;test&#x2F;merged  \</span><br><span class="line">--jar-file &#x2F;home&#x2F;hadoop&#x2F;student.jar \</span><br><span class="line">--class-name student  \</span><br><span class="line">--merge-key id</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th><strong>序号</strong></th>
<th><strong>参数</strong></th>
<th><strong>说明</strong></th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>–new-data (path)</td>
<td>HDFS 待合并的数据目录，合并后在新的数据集中保留</td>
</tr>
<tr>
<td>2</td>
<td>–onto(path)</td>
<td>HDFS合并后，重复的部分在新的数据集中被覆盖</td>
</tr>
<tr>
<td>3</td>
<td>–merge-key (col)</td>
<td>合并键，一般是主键ID</td>
</tr>
<tr>
<td>4</td>
<td>–jar-file (file)</td>
<td>合并时引入的jar包，该jar包是通过Codegen工具生成的jar包</td>
</tr>
<tr>
<td>5</td>
<td>–class-name (class)</td>
<td>对应的表名或对象名，该class类是包含在jar包中的</td>
</tr>
<tr>
<td>6</td>
<td>–target-dir (path)</td>
<td>合并后的数据在HDFS里存放的目录</td>
</tr>
</tbody></table>
<h5 id="metastore"><a href="#metastore" class="headerlink" title="metastore"></a>metastore</h5><p>记录了Sqoop job的元数据信息，如果不启动该服务，那么默认job元数据的存储目录为~/.sqoop，可在sqoop-site.xml中修改。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;sqoop metastore</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th><strong>序号</strong></th>
<th><strong>参数</strong></th>
<th><strong>说明</strong></th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>–shutdown</td>
<td>关闭metastore</td>
</tr>
</tbody></table>
<h4 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h4><p><a href="https://student-lp.iteye.com/blog/2157983" target="_blank" rel="noopener">https://student-lp.iteye.com/blog/2157983</a></p>
<p>尚硅谷Sqoop</p>

      
    </div>
    
  </div>
  
    
    <div class="copyright">
        <p><span>本文标题:</span><a  href="/2019/01/08/Sqoop/">Sqoop</a></p>
        <p><span>文章作者:</span><a  href="/" title="访问 清风笑丶 的个人博客">清风笑丶</a></p>
        <p><span>发布时间:</span>2019年01月08日 - 13时16分</p>
        <p><span>最后更新:</span>2020年01月12日 - 21时08分</p>
        <p>
            <span>原始链接:</span><a class="post-url" href="/2019/01/08/Sqoop/" title="Sqoop">https://www.hphblog.cn/2019/01/08/Sqoop/</a>
            <span class="copy-path" data-clipboard-text="原文: https://www.hphblog.cn/2019/01/08/Sqoop/　　作者: 清风笑丶" title=""></span>
        </p>
        <p>
            <span>许可协议:</span><i class="fa fa-creative-commons"></i> <a rel="license noopener" href="http://creativecommons.org/licenses/by-nc-sa/3.0/cn/" target="_blank" title="中国大陆 (CC BY-NC-SA 3.0 CN)" target = "_blank">"署名-非商用-相同方式共享 3.0"</a> 转载请保留原文链接及作者。
        </p>
    </div>



<nav id="article-nav">
  
    <a  href="/2019/01/10/Oozie/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption"><</strong>
      <div class="article-nav-title">
        
          Oozie
        
      </div>
    </a>
  
  
    <a  href="/2019/01/07/Flume%E6%A1%88%E4%BE%8BGanglia%E7%9B%91%E6%8E%A7/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">Flume案例Ganglia监控</div>
      <strong class="article-nav-caption">></strong>
    </a>
  
</nav>


  
</article>

    <div id="toc" class="toc-article">
    <strong class="toc-title">文章目录</strong>
    <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#简介"><span class="toc-number">1.</span> <span class="toc-text">简介</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#原理"><span class="toc-number">2.</span> <span class="toc-text">原理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#导入"><span class="toc-number">2.1.</span> <span class="toc-text">导入</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#导出"><span class="toc-number">2.2.</span> <span class="toc-text">导出</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#安装"><span class="toc-number">3.</span> <span class="toc-text">安装</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#案例"><span class="toc-number">4.</span> <span class="toc-text">案例</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#导入数据"><span class="toc-number">4.1.</span> <span class="toc-text">导入数据</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#RDBMS到HDFS"><span class="toc-number">4.1.1.</span> <span class="toc-text">RDBMS到HDFS</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#全部导入"><span class="toc-number">4.1.1.1.</span> <span class="toc-text">全部导入</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#查询导入"><span class="toc-number">4.1.1.2.</span> <span class="toc-text">查询导入</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#导入指定列"><span class="toc-number">4.1.1.3.</span> <span class="toc-text">导入指定列</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#使用sqoop关键字筛选查询导入数据"><span class="toc-number">4.1.1.4.</span> <span class="toc-text">使用sqoop关键字筛选查询导入数据</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#RDBMS到Hive"><span class="toc-number">4.1.2.</span> <span class="toc-text">RDBMS到Hive</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#RDBMS到HBase"><span class="toc-number">4.1.3.</span> <span class="toc-text">RDBMS到HBase</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#导出数据"><span class="toc-number">4.2.</span> <span class="toc-text">导出数据</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#HIVE到RDBMS"><span class="toc-number">4.2.1.</span> <span class="toc-text">HIVE到RDBMS</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#HDFS到RDBMS"><span class="toc-number">4.2.2.</span> <span class="toc-text">HDFS到RDBMS</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Sqoop-常用参数"><span class="toc-number">4.2.3.</span> <span class="toc-text">Sqoop 常用参数</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#import"><span class="toc-number">4.2.3.1.</span> <span class="toc-text">import</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#export"><span class="toc-number">4.2.3.2.</span> <span class="toc-text">export</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#hive"><span class="toc-number">4.2.3.3.</span> <span class="toc-text">hive</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Sqoop常用命令"><span class="toc-number">4.2.4.</span> <span class="toc-text">Sqoop常用命令</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#import-1"><span class="toc-number">4.2.4.1.</span> <span class="toc-text">import</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#export-1"><span class="toc-number">4.2.4.2.</span> <span class="toc-text">export</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#codegen"><span class="toc-number">4.2.4.3.</span> <span class="toc-text">codegen</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#eval"><span class="toc-number">4.2.4.4.</span> <span class="toc-text">eval</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#import-all-tables"><span class="toc-number">4.2.4.5.</span> <span class="toc-text">import-all-tables</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#job"><span class="toc-number">4.2.4.6.</span> <span class="toc-text">job</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#list-tables"><span class="toc-number">4.2.4.7.</span> <span class="toc-text">list-tables</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#merge"><span class="toc-number">4.2.4.8.</span> <span class="toc-text">merge</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#metastore"><span class="toc-number">4.2.4.9.</span> <span class="toc-text">metastore</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#参考资料"><span class="toc-number">4.2.5.</span> <span class="toc-text">参考资料</span></a></li></ol></li></ol></li></ol>
</div>
<style>
    .left-col .switch-btn {
        display: none;
    }
    .left-col .switch-area {
        display: none;
    }
</style>
<input type="button" id="tocButton" value="隐藏目录"  title="点击按钮隐藏或者显示文章目录">

<script src="https://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js"></script>

<script>
    var valueHide = "隐藏目录";
    var valueShow = "显示目录";
    if ($(".left-col").is(":hidden")) {
        $("#tocButton").attr("value", valueShow);
    }
    $("#tocButton").click(function() {
        if ($("#toc").is(":hidden")) {
            $("#tocButton").attr("value", valueHide);
            $("#toc").slideDown(320);
            $(".switch-btn, .switch-area").fadeOut(300);
        }
        else {
            $("#tocButton").attr("value", valueShow);
            $("#toc").slideUp(350);
            $(".switch-btn, .switch-area").fadeIn(500);
        }
    })
    if ($(".toc").length < 1) {
        $("#toc, #tocButton").hide();
        $(".switch-btn, .switch-area").show();
    }
</script>




<div class="bdsharebuttonbox">
	<a href="#" class="fx fa-weibo bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a>
	<a href="#" class="fx fa-weixin bds_weixin" data-cmd="weixin" title="分享到微信"></a>
	<a href="#" class="fx fa-qq bds_sqq" data-cmd="sqq" title="分享到QQ好友"></a>
	<a href="#" class="fx fa-facebook-official bds_fbook" data-cmd="fbook" title="分享到Facebook"></a>
	<a href="#" class="fx fa-twitter bds_twi" data-cmd="twi" title="分享到Twitter"></a>
	<a href="#" class="fx fa-linkedin bds_linkedin" data-cmd="linkedin" title="分享到linkedin"></a>
	<a href="#" class="fx fa-files-o bds_copy" data-cmd="copy" title="分享到复制网址"></a>
</div>
<script>window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"2","bdSize":"24"},"share":{}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];</script>




    
        <section class="changyan" id="comments">
  <!--<div id="uyan_frame"></div>-->
  <div id="SOHUCS"></div>
  <script charset="utf-8" type="text/javascript" src="https://changyan.sohu.com/upload/changyan.js"></script>
  <script type="text/javascript">
    window.changyan.api.config({
      appid: 'cyu9wWYgq',
      conf: 'prod_cca6a7c58b43f725f8489bdcee045320'
    });
  </script>
  <style>#feedAv{ margin-top: -250px !important;transform: scale(0) !important;}</style>
  <style>#pop_ad{ margin-top: -250px !important;transform: scale(0) !important;}</style>
</section>

    



    <div class="scroll" id="post-nav-button">
        
            <a  href="/2019/01/10/Oozie/" title="上一篇: Oozie">
                <i class="fa fa-angle-left"></i>
            </a>
        
        <a title="文章列表"><i class="fa fa-bars"></i><i class="fa fa-times"></i></a>
        
            <a  href="/2019/01/07/Flume%E6%A1%88%E4%BE%8BGanglia%E7%9B%91%E6%8E%A7/" title="下一篇: Flume案例Ganglia监控">
                <i class="fa fa-angle-right"></i>
            </a>
        
    </div>
    <ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2020/01/05/Flink%E5%88%9D%E8%AF%86/">Flink初识</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/06/10/Spark%E5%86%85%E6%A0%B8%E8%A7%A3%E6%9E%903/">Spark内核解析3</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/06/09/Spark%E5%86%85%E6%A0%B8%E8%A7%A3%E6%9E%902/">Spark内核解析2</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/06/09/Spark%E5%86%85%E6%A0%B8%E8%A7%A3%E6%9E%90/">Spark内核解析1</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/06/08/Spark%E4%B9%8BGraphX/">Spark之GraphX</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/06/07/Spark%E4%B9%8BStructuredStreaming/">Spark之StructuredStreaming</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/06/06/Spark%E4%B9%8BSparkStreaming%E7%9A%84DStream%E6%93%8D%E4%BD%9C/">Spark之SparkStreaming的DStream操作</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/06/05/Spark%E4%B9%8BSparkStreaming%E6%95%B0%E6%8D%AE%E6%BA%90/">Spark之SparkStreaming数据源</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/06/03/Spark%E4%B9%8BSparkStreaming%E7%90%86%E8%AE%BA%E7%AF%87/">Spark之SparkStreaming理论篇</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/06/01/Spark%E4%B9%8BSparkSQL%E6%95%B0%E6%8D%AE%E6%BA%90/">Spark之SparkSQL数据源</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/05/30/Spark%E4%B9%8BSparkSQL%E5%AE%9E%E6%88%98/">Spark之SparkSQL实战</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/05/30/Spark%E4%B9%8BSparkSQL/">Spark之SparkSQL理论篇</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/05/29/Spark%E4%B9%8BRDD%E5%AE%9E%E6%88%98%E7%AF%873/">Spark之RDD实战篇3</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/05/28/Spark%E4%B9%8BRDD%E5%AE%9E%E6%88%98%E7%AF%872/">Spark之RDD实战2</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/05/27/Spark%E4%B9%8BRDD%E5%AE%9E%E6%88%98%E7%AF%87/">Spark之RDD实战篇</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/05/27/Spark%E4%B9%8BRDD/">Spark之RDD理论篇</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/05/27/Spark%E4%B9%8BRDD%E7%90%86%E8%AE%BA%E7%AF%87/">Spark之RDD理论篇</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/05/26/Spark%E7%94%9F%E6%80%81%E5%9C%88%E5%8F%8A%E5%AE%89%E8%A3%85/">Spark生态圈及安装</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/05/26/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E5%93%88%E5%B8%8C%E8%A1%A8/">数据结构之哈希表</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/05/23/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E7%BA%A2%E9%BB%91%E6%A0%91/">数据结构之红黑树</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/05/22/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8BAVL%E6%A0%91/">数据结构之AVL树</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/05/14/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E5%B9%B6%E6%9F%A5%E9%9B%86/">数据结构之并查集</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/05/14/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E5%AD%97%E5%85%B8%E6%A0%91/">数据结构之字典树</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/05/10/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E5%A0%86%E4%B8%8E%E4%BC%98%E5%85%88%E9%98%9F%E5%88%97/">数据结构之堆与优先队列</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/05/07/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E4%BA%8C%E5%8F%89%E6%A0%91/">数据结构之二叉树</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/05/06/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E9%80%92%E5%BD%92/">数据结构之递归</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/05/04/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E9%93%BE%E8%A1%A8/">数据结构之链表</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/05/03/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E9%98%9F%E5%88%97/">数据结构之队列</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/05/03/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E6%A0%88/">数据结构之栈</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/05/02/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E6%95%B0%E7%BB%84/">数据结构之数组</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/05/02/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E5%89%8D%E6%8F%90/">数据结构与算法前置</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/28/Java%E9%A1%B9%E7%9B%AE%E6%9E%B6%E6%9E%84%E6%BC%94%E8%BF%9B%E5%92%8CSpringCloud%E6%80%BB%E7%BB%93/">Java项目架构演进和SpringCloud总结</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/27/SpringCloud%E4%B8%8ESpringConfig%E5%88%86%E5%B8%83%E5%BC%8F%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83/">SpringCloud与SpringConfig分布式配置中心</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/27/SpringCloud%E4%B8%8Ezuul/">SpringCloud与zuul</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/27/SpringCloud%E4%B8%8EHystrix%E6%96%AD%E8%B7%AF%E5%99%A8/">SpringCloud与Hystrix断路器</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/26/SpringCloud%E4%B8%8EFeign%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/">SpringCloud与Feign</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/25/SpringCloud%E7%9A%84Ribbon%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/">SpringCloud的Ribbon负载均衡</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/23/SpringCloud%E6%B3%A8%E5%86%8C%E4%B8%8E%E5%8F%91%E7%8E%B0Eureka/">SpringCloud注册与发现Eureka</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/21/SpringCloud%E4%B8%8EREST%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%84%E5%BB%BA/">微服务与SpringCloud</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/18/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E4%B8%8ESpringCloud/">微服务与SpringCloud</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/14/SpringBoot%E5%92%8C%E7%9B%91%E6%8E%A7%E7%AE%A1%E7%90%86/">SpringBoot和监控管理</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/14/SpringBoot%E4%B8%8ESpringCloud%E9%9B%86%E6%88%90/">SpringBoot与SpringCloud集成</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/13/SpringBoot%E4%B8%8EDubbo%E9%9B%86%E6%88%90/">SpringBoot与Dubbo集成</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/13/SpringBoot%E5%AE%89%E5%85%A8/">SpringBoot与安全</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/13/SpringBoot%E4%B8%8E%E4%BB%BB%E5%8A%A1/">SpringBoot与任务</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/12/SpringBoot%E5%92%8CElasticSearch%E9%9B%86%E6%88%90/">SpringBoot和Elasticsearch集成</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/12/Elasticsearch%E7%AE%80%E4%BB%8B/">Elasticsearch简介</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/11/SpringBoot%E5%92%8CRabbitMQ%E9%9B%86%E6%88%90/">SpringBoot和RabbitMQ集成</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/11/SpringBoot%E5%92%8C%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/">消息队列RabbitMQ</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/10/SpringBoot%E4%B8%8ERedis%E7%BC%93%E5%AD%98/">SpringBoot与Redis缓存</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/09/SpringBoot%E5%92%8C%E7%BC%93%E5%AD%98/">SpringBoot和缓存</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/09/SpringBoot%E4%B8%8EJPA/">SpringBoot与JPA</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/08/SpringBoot%E4%B8%8EMybatis%E7%9A%84%E9%9B%86%E6%88%90/">SpringBoot与Mybatis的集成</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/08/SpringBoot%E6%95%B0%E6%8D%AE%E8%AE%BF%E9%97%AE/">SpringBoot数据访问</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/07/DockerFile/">DockerFile</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/06/Docker%E5%AD%98%E5%82%A8%E5%8D%B7/">Docker存储卷</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/06/Dokcer%E7%BD%91%E7%BB%9C/">Dokcer网络</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/05/Docker%E7%9A%84%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/">Docker的基础命令</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/04/Docker%E5%88%9D%E8%AF%86%E4%B8%8E%E5%AE%89%E8%A3%85/">Docker初识与安装</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/03/SpringBoot%E4%BD%BF%E7%94%A8%E5%A4%96%E7%BD%AE%E7%9A%84Servlet%E5%AE%B9%E5%99%A8/">SpringBoot使用外置的Servlet容器</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/02/SpringBoot%E9%85%8D%E7%BD%AE%E5%B5%8C%E5%85%A5%E5%BC%8FServlet%E5%AE%B9%E5%99%A8/">SpringBoot配置嵌入式Servlet容器</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/03/29/SpringBoot%E4%B9%8BSpringMVC%E8%87%AA%E5%8A%A8%E9%85%8D%E7%BD%AE/">SpringBoot之SpringMVC自动配置</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/03/29/SpringBoot%E4%B9%8BThymeleaf/">SpringBoot之Thymeleaf</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/03/29/SpringBoot%E7%9A%84Web%E5%BC%80%E5%8F%91/">SpringBoot的Web开发</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/03/28/SpringBoot%E7%9A%84%E6%97%A5%E5%BF%97%E6%A1%86%E6%9E%B6/">SpringBoot的日志框架</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/03/28/SpringBoot%E8%87%AA%E5%8A%A8%E8%A3%85%E9%85%8D%E6%8E%A2%E7%A9%B6/">SpringBoot自动装配探究</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/03/25/SpringBoot%E7%9A%84%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/">SpringBoot的配置文件</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/03/25/SpringBoot%E5%88%9D%E8%AF%86/">SpringBoot初识</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/03/24/SSM%E9%9B%86%E6%88%90/">SSM集成</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/03/19/SSM%E6%95%B4%E5%90%88/">SSM整合</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/03/19/Mybatis%E4%B9%8B%E5%8A%A8%E6%80%81SQL/">Mybatis之动态SQL</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/03/19/Mybatis%E7%9A%84resultMap%E8%87%AA%E5%AE%9A%E4%B9%89%E6%98%A0%E5%B0%84/">Mybatis的resultMap自定义映射</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/03/18/MyBatis%E7%9A%84CURD/">MyBatis的CURD</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/03/18/MyBatis%E5%85%A8%E5%B1%80%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E5%92%8C%E6%98%A0%E5%B0%84%E6%96%87%E4%BB%B6/">MyBatis全局配置文件和映射文件</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/03/16/Mybatis%E5%85%A5%E9%97%A8/">Mybatis入门</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/03/13/Spring%E5%92%8CSpringMVC%E6%95%B4%E5%90%88/">Spring和SpringMVC整合</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/03/12/SpringMV%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90/">SpringMV工作流程分析</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/03/11/SpringMVC%E8%BF%9B%E9%98%B6/">SpringMVC处理Json、文件上传、拦截器</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/03/07/Spring%E5%A4%84%E7%90%86%E8%AF%B7%E6%B1%82%E6%88%96%E5%93%8D%E5%BA%94%E6%95%B0%E6%8D%AE/">SpringMVC处理请求或响应数据</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/03/06/SpringMVC%E6%A6%82%E8%BF%B0/">SpringMVC概述</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/03/05/Spring%E4%BA%8B%E5%8A%A1%E6%A6%82%E8%BF%B0/">Spring声明式事务</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/03/05/JdbcTemplate/">JdbcTemplate</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/03/03/AOP%E6%A6%82%E8%BF%B0/">AOP概述</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/03/02/SpringIOC%E5%AE%B9%E5%99%A8%E5%92%8CBean%E7%9A%84%E9%85%8D%E7%BD%AE/">Spring IOC容器和Bean的配置</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/03/02/Spring%E6%A6%82%E8%BF%B0/">Spring概述</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/18/Hive%E8%B0%83%E4%BC%98/">Hive调优</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/17/Hive%E6%9F%A5%E8%AF%A2/">Hive查询</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/16/Hive%E6%95%B0%E6%8D%AE%E6%8D%AE%E7%B1%BB%E5%9E%8B/">Hive数据据类型 DDL DML</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/15/Kafka-API%E5%AE%9E%E6%88%98/">KafkaAPI实战</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/11/Git%E4%BD%BF%E7%94%A8/">Git使用</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/10/Oozie/">Oozie</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/08/Sqoop/">Sqoop</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/07/Flume%E6%A1%88%E4%BE%8BGanglia%E7%9B%91%E6%8E%A7/">Flume案例Ganglia监控</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/06/ZooKeeper%E7%9A%84%E5%AE%89%E8%A3%85%E5%92%8CAPI/">ZooKeeper的安装和API</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/05/Zookeeper%E5%85%A5%E9%97%A8/">Zookeeper入门</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/31/HBase%E4%BC%98%E5%8C%96/">HBase优化</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/31/HBase%E7%9A%84Shell%E5%91%BD%E4%BB%A4%E5%92%8CJavaAPI/">HBase的Shell命令和JavaAPI</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/30/HBase%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B%E5%92%8C%E8%AF%BB%E5%86%99%E5%8E%9F%E7%90%86/">HBase数据模型和读写原理</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/30/Hbase%E5%8E%9F%E7%90%86%E5%92%8C%E5%AE%89%E8%A3%85/">HBase原理和安装</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/28/MapReduce%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B2/">MapReduce高级编程2</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/28/MapReduce%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B/">MapReduce高级编程</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/25/MapReduce%E7%BC%96%E7%A8%8B%E5%88%A8%E6%9E%90/">MapReduce源码刨析</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/24/MapReduce%E7%9A%84%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6/">MapReduce的工作机制</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/22/Mapreduce/">MapReduce入门和优化方案</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/20/Hadoop%E7%9A%84RPC/">Hadoop的RPC工作原理</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/20/Hadoop%E7%9A%84IO%E6%93%8D%E4%BD%9C/">Hadoop的I/O操作</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/19/Yarn/">Yarn</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/19/HDFS%E9%AB%98%E7%BA%A7%E5%8A%9F%E8%83%BD/">HDFS高级功能</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/18/HDFS%E7%9A%84%E6%93%8D%E4%BD%9CSHELL%E5%92%8CAPI/">HDFS的操作SHELL和API</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/17/Hadoop%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9FHDFS/">Hadoop分布式文件系统HDFS</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/17/Hadoop%E7%AE%80%E4%BB%8B%E4%B8%8E%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%89%E8%A3%85/">Hadoop简介与分布式安装</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/16/Elasticsearch%E7%9A%84JavaAPI/">Elasticsearch的JavaAPI</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/16/Elasticsearch%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%BA%E5%88%B6%E6%8E%A2%E7%A9%B6/">Elasticsearch分布式机制探究</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/16/Elasticsearch%E8%81%9A%E5%90%88%E5%88%86%E6%9E%90/">Elasticsearch聚合分析</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/16/Elasticsearch%E5%A2%9E%E5%88%A0%E6%94%B9%E6%9F%A5/">Elasticsearch增删改查</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/15/ElasticSearch%E7%B4%A2%E5%BC%95/">ElasticSearch索引</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/15/Elasticsearch%E7%AE%80%E4%BB%8B%E4%B8%8E%E5%AE%89%E8%A3%85/">Elasticsearch简介与安装</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/12/MongoDB%E8%BF%9B%E9%98%B6/">MongoDB进阶</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/11/MongoDB%E8%81%9A%E5%90%88/">MongoDB聚合</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/10/MongoDB%E7%B4%A2%E5%BC%95/">MongoDB索引</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/09/MongoDB%E6%9F%A5%E8%AF%A2/">MongoDB查询</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/09/MongoDB%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/">MongoDB基础命令</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/08/MongoDB%E5%85%A5%E9%97%A8/">MongoDB入门</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/07/Redis%E7%9A%84%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F/">Redis的集群模式</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/07/Redis%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/">Redis主从复制</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/07/Redis%E6%8C%81%E4%B9%85%E5%8C%96/">Redis持久化</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/07/Redis%E4%BA%8B%E5%8A%A1/">Redis事务</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/04/memcached/">Memcached</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/03/Redis/">Redis</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/03/Hive/">Hive</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/16/Flume/">Flume架构</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/16/kafka%E5%B7%A5%E4%BD%9C%E6%B5%81%E5%88%86%E6%9E%90/">Kafka深度解析</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/14/Kafka%E5%91%BD%E4%BB%A4%E6%93%8D%E4%BD%9C/">Kafka命令操作</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/14/Kafka%E4%BB%8B%E7%BB%8D%E4%B8%8E%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/">Kafka与消息队列</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/14/Kafka%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/">Kafka和的安装与配置</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/12/Java%E8%99%9A%E6%8B%9F%E6%9C%BA------JVM%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7/">Java虚拟机------JVM分析工具</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/12/Java%E8%99%9A%E6%8B%9F%E6%9C%BA-JVM%E5%B8%B8%E8%A7%81%E5%8F%82%E6%95%B0/">Java虚拟机--------JVM常见参数</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/11/Java%E8%99%9A%E6%8B%9F%E6%9C%BA------%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/">Java虚拟机------垃圾收集器</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/10/Java%E8%99%9A%E6%8B%9F%E6%9C%BA------JVM%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F/">Java虚拟机------JVM内存区域</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/10/Java%E8%99%9A%E6%8B%9F%E6%9C%BA------JVM%E4%BB%8B%E7%BB%8D/">Java虚拟机------JVM介绍</a></li></ul>
    
<script src="https://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js"></script>

    <script>
        $(".post-list").addClass("toc-article");
        // $(".post-list-item a").attr("target","_blank");
        $("#post-nav-button > a:nth-child(2)").click(function() {
            $(".fa-bars, .fa-times").toggle();
            $(".post-list").toggle(300);
            if ($(".toc").length > 0) {
                $("#toc, #tocButton").toggle(200, function() {
                    if ($(".switch-area").is(":visible")) {
                        $("#toc, .switch-btn, .switch-area").toggle();
                        $("#tocButton").attr("value", valueHide);
                        }
                    })
            }
            else {
                $(".switch-btn, .switch-area").fadeToggle(300);
            }
        })
    </script>




    <script>
        
    </script>

</div>
      <footer id="footer">
    <div class="outer">
        <div id="footer-info">
            <div class="footer-left">
                &copy; 2020 清风笑丶
            </div>
            <div class="footer-right">
                <a href="http://hexo.io/" target="_blank">Hexo &nbsp;&nbsp;</a><a href="https://github.com/maochunguang" target="_blank">Blog</a> by tommy
            </div>
        </div>
        
            <div class="visit">
                
                    <span id="busuanzi_container_site_pv" style='display:none'>
                        <span id="site-visit" >极客到访数: 
                            <span id="busuanzi_value_site_uv"></span>
                        </span>
                    </span>
                
                
                    <span>, </span>
                
                
                    <span id="busuanzi_container_page_pv" style='display:none'>
                        <span id="page-visit">本页阅读量: 
                            <span id="busuanzi_value_page_pv"></span>
                        </span>
                    </span>
                
            </div>
        
    </div>
</footer>

    </div>
    
<script src="https://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js"></script>


<script src="/js/main.js"></script>


    <script>
        $(document).ready(function() {
            var backgroundnum = 2;
            var backgroundimg = "url(/background/bg-x.jpg)".replace(/x/gi, Math.ceil(Math.random() * backgroundnum));
            $("#mobile-nav").css({"background-image": backgroundimg,"background-size": "cover","background-position": "center"});
            $(".left-col").css({"background-image": backgroundimg,"background-size": "cover","background-position": "center"});
        })
    </script>


<!-- Google Analytics -->
<script type="text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-129731340-1', 'auto');
ga('send', 'pageview');

</script>
<!-- End Google Analytics -->



	<script>
	var _hmt = _hmt || [];
	(function() {
	  var hm = document.createElement("script");
	  hm.src = "//hm.baidu.com/hm.js?a138f5cac94c7795df86f17cea34efc4";
	  var s = document.getElementsByTagName("script")[0]; 
	  s.parentNode.insertBefore(hm, s);
	})();
	</script>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<div class="scroll" id="scroll">
    <a href="#"><i class="fa fa-arrow-up"></i></a>
    <a href="#comments"><i class="fa fa-comments-o"></i></a>
    <a href="#footer"><i class="fa fa-arrow-down"></i></a>
</div>
<script>
    $(document).ready(function() {
        if ($("#comments").length < 1) {
            $("#scroll > a:nth-child(2)").hide();
        };
    })
</script>

<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>

  <script language="javascript">
    $(function() {
        $("a[title]").each(function() {
            var a = $(this);
            var title = a.attr('title');
            if (title == undefined || title == "") return;
            a.data('title', title).removeAttr('title').hover(
            function() {
                var offset = a.offset();
                $("<div id=\"anchortitlecontainer\"></div>").appendTo($("body")).html(title).css({
                    top: offset.top - a.outerHeight() - 15,
                    left: offset.left + a.outerWidth()/2 + 1
                }).fadeIn(function() {
                    var pop = $(this);
                    setTimeout(function() {
                        pop.remove();
                    }, pop.text().length * 800);
                });
            }, function() {
                $("#anchortitlecontainer").remove();
            });
        });
    });
</script>


  </div>
</body>
</html>